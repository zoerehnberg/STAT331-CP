---
title: "Data Joins + Transformations"
format: 
  revealjs:
    theme: default
editor: source
self-contained: true
---

```{r setup}
#| include: false
#| message: false
library(tidyverse)
library(palmerpenguins)
```

## Monday, April 24

Today we will...

-   Review PA 3: Identify the Mystery College
-   New Material
    -   Pivoting with `tidyr`
    -   Joining with `dplyr`
-   [PA 4: Military Spending](https://earobinson95.github.io/stat331-calpoly/practice-activities/PA4-military-spending)
-   [Bonus Challenge: Murdery Mystery in SQL City](https://earobinson95.github.io/stat331-calpoly/bonus-challenges/bonus-challenge-murder-sql-city)

## Lab 3: Familiar Words -- Sketch it out!

"For each demographic group listed below, determine **all** words in this study that were the most **and** least familiar, **on average**."

![](https://github.com/earobinson95/stat331-calpoly/blob/master/lab-assignments/Lab3-dplyr/q11-q13-sketch.png?raw=true)

# Data Layouts

## Tidy Data

Tidy data...

-   is rectangular.
-   has variables as rows and observations as columns.
-   **has different formats for different tasks.**

![R4DS](https://r4ds.hadley.nz/images/tidy-1.png)

## Consequences of Messy Data

![Illustration by Allison Horst](https://www.openscapes.org/img/blog/tidydata/tidydata_2.jpg)

-   Tidy: use the same tools in similar ways for different datasets.
-   Messy: create unique tools that are difficult to generalize.


## Creating Tidy Data

We may need to **transform** our data to turn it into the **version of tidy** that is best for a task at hand.

![Illustration by Allison Horst](https://www.openscapes.org/img/blog/tidydata/tidydata_4.jpg)


## Creating Tidy Data

We want to look at `mean` **cereal nutrients** based on `shelf`.

+ The data are in a **wide** format -- a separate column for each nutrient.
+ Transforming the data will make plotting easier.

```{r}
#| echo: true
#| eval: false
library(liver)
data(cereal)
head(cereal)
```

```{r}
#| eval: true
#| echo: false
library(liver)
data(cereal)
head(cereal) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "210px") |> 
  kableExtra::kable_styling(font_size = 30)
```

## Creating Tidy Data

::: panel-tabset

## Wide

```{r}
#| echo: true
#| code-line-numbers: "2-3"
#| code-fold: true
cereal_wide <- cereal |> 
  group_by(shelf) |> 
  summarise(across(calories:vitamins, mean))
```

```{r}
#| eval: true
#| echo: false
cereal_wide|> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "210px") |> 
  kableExtra::kable_styling(font_size = 30)
```

## Wide Plot

```{r}
#| echo: true
#| code-line-numbers: "5-8"
#| fig-height: 4
#| fig-width: 6
#| fig-align: center
#| code-fold: true
my_colors <- c("calories_col" = "steelblue", "sugars_col" = "orange3")

cereal_wide |> 
  ggplot() +
  geom_point(aes(x = shelf, y = calories, color = "calories_col")) +
  geom_line(aes(x = shelf, y = calories, color = "calories_col")) + 
  geom_point(aes(x = shelf, y = sugars, color = "sugars_col")) +
  geom_line(aes(x = shelf, y = sugars, color = "sugars_col")) +
  scale_color_manual(values = my_colors, labels = names(my_colors)) +
  labs(x = "Shelf", y = "", subtitle = "Mean Amount", color = "Nutrient")
```

## Long

```{r}
#| echo: true
#| code-line-numbers: "5-6"
#| code-fold: true
cereal_long<- cereal |> 
  pivot_longer(cols = calories:vitamins,
               names_to = "Nutrient",
               values_to = "Amount") |> 
  group_by(shelf, Nutrient) |> 
  summarise(mean_amount = mean(Amount))
```

```{r}
#| eval: true
#| echo: false
cereal_long |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "400px") |> 
  kableExtra::kable_styling(font_size = 30)
```

## Long Plot

```{r}
#| echo: true
#| code-line-numbers: "2-4"
#| fig-height: 4
#| fig-width: 6
#| fig-align: center
#| code-fold: true
cereal_long |> 
  ggplot(aes(x = shelf, 
             y = mean_amount, 
             color = Nutrient)) +
  geom_point() +
  geom_line() +
  labs(x = "Shelf", y = "", subtitle = "Mean Amount")
```
:::


# Pivoting Data

::: columns
::: column
![Tidyexpalin animation by Kelsey Gonzalez](https://github.com/gadenbuie/tidyexplain/raw/main/images/static/png/original-dfs-tidy.png)
:::

::: column
![](https://github.com/gadenbuie/tidyexplain/raw/main/images/tidyr-pivoting.gif)
:::
:::

## Manual Method

Consider daily rainfall observed in SLO in January 2023.

+ The data is in a human-friendly form (like a calendar).
+ Each week has a row, and each day has a column.

![[Data source](cesanluisobispo.ucanr.edu)](images/slo-rainfall.jpg)

How would you **manually** convert this to **long format**?


## Manual Method: Steps

::: incremental
1.  Create a new column: `Day_of_Week`.

2.  Create a new column: `Rainfall` (hold daily rainfall values).

3.  Now we have three columns (`Week`, `Day_of_Week`, and `Rainfall`) -- start moving Sunday values over.

4.  Duplicate `Week` 1-5 and copy Monday values over.

5.  Duplicate `Week` 1-5 and copy Tuesday values over.

6.  Continue for the rest of the days of the week.

7.  You may want to `arrange()` by `Week` to get the rainfall values chronological order.
:::

## Computational Approach

![](images/slo-rainfall-sketch.png)

We can use `pivot_longer()` to turn a **wide** dataset into a **long(er)** dataset.


## `pivot_longer()`

Take a **wide** dataset and turn it into a **long** daaset.

+ `cols` -- specify the columns that should be pivoted.
  + Do **not** include the names of ID columns (columns to not be pivoted).
+ `names_to` -- the name of the new column containing the old column names.
+ `values_to` -- the name of the new column containing the old  column values.


## `pivot_longer()`

```{r}
#| echo: true
#| code-line-numbers: "6-8"
#| eval: false
library(readxl)
slo_rainfall <- read_xlsx("data/2023-rainfall-slo.xlsx")

slo_rainfall |> 
  mutate(across(Sunday:Saturday, as.numeric)) |> 
  pivot_longer(cols      = Sunday:Saturday,
               names_to  = "Day_of_Week",
               values_to = "Daily_Rainfall")
```

```{r}
#| eval: true
#| echo: false
library(readxl)
slo_rainfall <- read_xlsx("data/2023-rainfall-slo.xlsx")

slo_rainfall |> 
  mutate(across(Sunday:Saturday, as.numeric)) |> 
  pivot_longer(cols      = Sunday:Saturday,
               names_to  = "Day_of_Week",
               values_to = "Daily_Rainfall")|> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "400px") |> 
  kableExtra::kable_styling(font_size = 30)
```


## `pivot_wider()`

Take a **long** dataset and turn it into a **wide** daaset.

+ `id_cols` -- specify the column(s) that contain the ID for unique rows in the wide dataset.
+ `names_from` -- the name of the column containing the new column names.
+ `values_from` -- the name of the column containing the new  column values.


## `pivot_wider()`

We calculate the mean amount of protein for cereals on each shelpf and for each manufacturer.

```{r}
#| echo: true
#| eval: false
mean_protein <- cereal |> 
  group_by(manuf, shelf) |> 
  summarize(mean_protein = mean(protein))
```

```{r}
#| eval: true
#| echo: false
mean_protein <- cereal |> 
  group_by(manuf, shelf) |> 
  summarize(mean_protein = mean(protein))

mean_protein |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "400px") |> 
  kableExtra::kable_styling(font_size = 30)
```


## `pivot_wider()`

```{r}
#| eval: false
#| echo: true
mean_protein |> 
  arrange(shelf) |> 
  pivot_wider(id_cols = manuf,
              names_from = shelf,
              values_from = mean_protein)
```

```{r}
#| eval: true
#| echo: false
mean_protein |> 
  arrange(shelf) |> 
  pivot_wider(id_cols = manuf,
              names_from = shelf,
              values_from = mean_protein) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "420px") |> 
  kableExtra::kable_styling(font_size = 30)
```


## Better names in `pivot_wider()`


```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "6"
mean_protein |> 
  arrange(shelf) |> 
  pivot_wider(id_cols = manuf,
              names_from = shelf,
              values_from = mean_protein,
              names_prefix = "Shelf_")
```

```{r}
#| eval: true
#| echo: false
mean_protein |> 
  arrange(shelf) |> 
  pivot_wider(id_cols = manuf,
              names_from = shelf,
              values_from = mean_protein,
              names_prefix = "Shelf_") |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "420px") |> 
  kableExtra::kable_styling(font_size = 30)
```

# Data Joins

## Relational Data

Multiple, interconnected tables of data are called **relational**.

+ It is the *relation* between data sets, not just the individual data sets themselves, that are important.

![IMDb movie relational data](https://relational.fit.cvut.cz/assets/img/datasets-generated/imdb_ijs.svg)

```{r imdb-data}
#| eval: false
#| include: false
#| message: false
#| warning: false
library(RMariaDB)
library(dm)
`
# IMDb
con <- dbConnect(
  drv = RMariaDB::MariaDB(), 
  username = "guest",
  password = "relational", 
  host = "relational.fit.cvut.cz", 
  port = 3306,
  dbname = "imdb_small"
)
dbListTables(con)

my_dm <- dm_from_src(con)

actors <- my_dm$actors |> 
  as.data.frame()
write_csv(actors, "data/actors.csv", na = "")

directors <- my_dm$directors |> 
  as.data.frame()
write_csv(directors, "data/directors.csv", na = "")

directors_genres <- my_dm$directors_genres |> 
  as.data.frame()
write_csv(directors_genres, "data/directors_genres.csv", na = "")

movies <- my_dm$movies |> 
  as.data.frame()
write_csv(movies, "data/movies.csv", na = "")

movies_directors <- my_dm$movies_directors |> 
  as.data.frame()
write_csv(movies_directors, "data/movies_directors.csv", na = "")

movies_genres <- my_dm$movies_genres |> 
  as.data.frame()
write_csv(movies_genres, "data/movies_genres.csv", na = "")

roles <- my_dm$roles |> 
  as.data.frame()
write_csv(roles, "data/roles.csv", na = "")

dbDisconnect(con)
rm(con, my_dm)
```

```{r imdb-data2}
#| eval: true
#| include: false
#| message: false
#| warning: false

actors <- read_csv("data/actors.csv")

directors <- read_csv("data/directors.csv")

directors_genres <- read_csv("data/directors_genres.csv")

movies <- read_csv("data/movies.csv")

movies_directors <- read_csv("data/movies_directors.csv")

movies_genres <- read_csv("data/movies_genres.csv")

roles <- read_csv("data/roles.csv")
```


## Data Joins

We can **combine** (join) data tables based on their relations.

::: columns
::: column
**Mutating joins**

Add *variables* from a new dataframe to observations in an existing dataframe.

`full_join()`, `left_join()`, `right_join()`, `inner_join()`, `outer_join()`
:::

::: column
**Filtering Joins**

Filter *observations* based on values in new dataframe.

`semi_join()`, `anti_join()`
:::
:::


## Keys

A key uniquely identifies an observation in a data set.

+ To combine (join) two datasets, the key needs to be present in both.

. . .

![](images/imdb-keys.png)


## `inner_join()`

Keeps obsertvations when their keys are present in **both** datasets.


:::: {.columns}
::: {.column width="50%"}
![](images/join_xy.png)
:::
::: {.column width="50%"}
![](images/inner_join.png)

:::
::::


## `inner_join()`: IMDb Example

```{r}
directors_genres_subset <- directors_genres |>
  filter(director_id %in% c(429, 2931, 11652, 14927, 15092)) |> 
  group_by(director_id) |> 
  slice_max(order_by = prob, n = 2, with_ties = F)

movies_directors_subset <- movies_directors |> 
  filter(director_id %in% c(429, 9247, 11652, 14927, 15092))

directors_subset <- directors |> 
  filter(id %in% c(429, 9247, 11652, 14927, 15092))
```

:::: {.columns}
::: {.column width="50%"}

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
directors_genres
```

```{r}
#| eval: true
#| echo: false
directors_genres_subset |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "160px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::
::: {.column width="50%"}

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
movies_directors
```

```{r}
#| eval: true
#| echo: false
movies_directors_subset |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "160px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::
::::

<font size = 6>

ID: 429, **2931**, 11652, 14927, 15092  &emsp; &emsp; &ensp;  ID: 429, **9247**, 11652, 14927, 15092

</font>

. . .

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
inner_join(directors_genres, movies_directors)
```

```{r}
#| eval: true
#| echo: false
inner_join(directors_genres_subset, movies_directors_subset) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "160px") |> 
  kableExtra::kable_styling(font_size = 30)
```

<font size = 6>

ID: 429, ~~**2931**~~, ~~**9247**~~, 11652, 14927, 15092

</font>


## `inner_join()`: IMDb Example

What if our **key** does not have the same name?

:::: {.columns}
::: {.column width="50%"}

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
directors_genres
```

```{r}
#| eval: true
#| echo: false
directors_genres_subset |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "170px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::
::: {.column width="50%"}

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
directors
```

```{r}
#| eval: true
#| echo: false
directors_subset |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "170px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::
::::

. . .

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "3"
inner_join(directors_genres, 
           directors, 
           by = c("director_id" = "id"))
```

```{r}
#| eval: true
#| echo: false
inner_join(directors_subset,
           directors_genres_subset,
           by = c("id" = "director_id")) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "170px") |> 
  kableExtra::kable_styling(font_size = 30)
```


## Mutating Joins

-   `left_join()` -- keep only (and all) observations in the left data set

-   `right_join()` -- keep only (and all) observations in the right data set 

-   `full_join()` -- keep  all observations in both data sets

<center>

![](images/joins.png){width=70%}

</center>

## Mutating Joins

Which directors would **remain** for each of the following?

<font size = 6>

-   `left_join(directors_genres, movies_directors)`
-   `right_join(directors_genres, movies_directors)`
-   `full_join(directors_genres, movies_directors)`

</font>

::: columns
::: column
```{r}
#| eval: false
#| echo: true
directors_genres |> 
  distinct(director_id)
```

```{r}
#| eval: true
#| echo: false
directors_genres_subset |> 
  distinct(director_id) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "320px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::

::: column
```{r}
#| eval: false
#| echo: true
movies_directors |> 
  distinct(director_id)
```

```{r}
#| eval: true
#| echo: false
movies_directors_subset |> 
  distinct(director_id) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "320px") |> 
  kableExtra::kable_styling(font_size = 30)
```
:::
:::


## Filtering Joins: `semi_join()`

Keeps observations when their keys are present in **both** datasets, **but only keeps variables from the first dataset**.

:::: {.columns}
::: {.column width="60%"}

![](images/semi1.png)
:::
::: {.column width="15%"}

<br>

::: {.r-fit-text}
&rarr; &emsp;
:::

:::
::: {.column width="25%"}

![](images/semi2.png)

:::
::::


## Filtering Joins: `semi_join()`

::: panel-tabset

### `semi_join()`

```{r}
#| echo: true
#| eval: false
semi_join(directors_genres, movies_directors)
```

```{r}
#| eval: true
#| echo: false
semi_join(directors_genres_subset, movies_directors_subset) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "320px") |> 
  kableExtra::kable_styling(font_size = 30)
```

Movie Directors: 429, ~~**2931**~~, 11652, 14927, 15092

### Connection to `filter()`

```{r}
#| echo: true
#| eval: false
directors_genres |>
  filter(director_id %in% movies_directors$director_id)
```

```{r}
#| eval: true
#| echo: false
directors_genres_subset |>
  filter(director_id %in% movies_directors_subset$director_id) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "320px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::


## Filtering Joins: `anti_join()`

**Removes** observations when their keys are present in **both** datasets, and **only keeps variables from the first dataset**.

:::: {.columns}
::: {.column width="60%"}

![](images/semi1.png)
:::
::: {.column width="15%"}

<br>

::: {.r-fit-text}
&rarr; &emsp;
:::

:::
::: {.column width="25%"}

<br>

![](images/anti2.png)

:::
::::


## Filtering Joins: `anti_join()`

::: panel-tabset

### `anti_join()`

```{r}
#| echo: true
#| eval: false
anti_join(directors_genres, movies_directors)
```

```{r}
#| eval: true
#| echo: false
anti_join(directors_genres_subset, movies_directors_subset) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "200px") |> 
  kableExtra::kable_styling(font_size = 30)
```

Movie Directors: ~~429~~, **2931**, ~~11652~~, ~~14927~~, ~~15092~~

### Connection to `filter()`

```{r}
#| echo: true
#| eval: false
directors_genres |>
  filter(!director_id %in% movies_directors$director_id)
```

```{r}
#| eval: true
#| echo: false
directors_genres_subset |>
  filter(!director_id %in% movies_directors_subset$director_id) |> 
  knitr::kable() |> 
  kableExtra::scroll_box(height = "200px") |> 
  kableExtra::kable_styling(font_size = 30)
```

:::


## Piping Joins

Remember: the dataset you pipe in becomes the **first argument** of the function you are piping into!

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
inner_join(directors_genres, movies_directors)
```

...is equivalent to...

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
directors_genres |> 
  inner_join(movies_directors)
```


## [PA 4: Military Spending](https://earobinson95.github.io/stat331-calpoly/practice-activities/PA4-military-spending)

Today you will be tidying messy data to explore the relationship between countries of the world and military spending.

+ **Due Wednesday, 4/26 at 10:00am**

## [Bonus Challenge: Murder in SQL City](https://earobinson95.github.io/stat331-calpoly/bonus-challenges/bonus-challenge-murder-in-sql-city.html)

For this challenge, you will be using table joins to solve a murder mystery!

+ **Due Monday, 5/8 at 11:59pm**

<center>
![](images/sql-murder-relational-data.png)
</center>


## To do...

-   **PA 4: Military Spending**
    -   Due Wednesday, 4/26 at 10:00am
-   **Bonus Challenge: Murder Mystery in SQL City**
    -   Due Monday, 5/8 at 11:59pm


## Wednesday, January 25th

Today we will...

-   Review Lab 3
-   Review PA 4: Military Spending
-   Housekeeping items...
    -   Providing References in Labs + Challenges
    -   Clean variable names
    -   Lifecycle stages
    -   `dplyr` package updates
    -   Saving & Piping Data Joins
-   Extensions to Relational Data
-   Lab 4: Avocado Prices
-   Challenge 3: Avocado Toast Ate My Mortgage

## Getting Help and using Chat GPT

::: columns
::: column
![](images/stack_overflow.PNG) <br> ![](images/help.PNG)
:::

::: column

```{=html}
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8">
</script>
```

 <!--<blockquote class="twitter-tweet">

<p lang="en" dir="ltr">

My cheating policy this quarter for #ChatGPT: Treat AI like a human tutor. <br><br>Asking a tutor to help explain a homework concept to you or help debug your code? <br>Totally fine! <br><br>Having a tutor do your homework for you? Talking to a tutor during an exam?<br> Not acceptable. <br><br>ü§∑‚Äç‚ôÄÔ∏è

</p>

--- Kelly Bodwin (@KellyBodwin) <a href="https://twitter.com/KellyBodwin/status/1613112086925824000?ref_src=twsrc%5Etfw">January 11, 2023</a>

</blockquote>  -->

:::
:::

## Lab 3: Distinct number of words

<br>

::: columns
::: column
```{r}
#| eval: false
#| echo: true
count(distinct(hiphop_clean, word))
```

<br>

```{r}
#| eval: false
#| echo: true
hiphop_clean |> 
  distinct(word) |> 
  count()
```

<br>

$f(g(h(x)))$

in piping syntax is

`x |> h() |> g() |> f()`
:::

::: column
```{r}
#| eval: false
#| echo: true
n_distinct(hiphop_clean$word)
```

<br>

```{r}
#| eval: false
#| echo: true
hiphop_clean |> 
  pull(word) |> 
  n_distinct()
```
:::
:::

## Clean variable names with [`library(janitor)`](https://sfirke.github.io/janitor/)

```{r}
#| include: false
library(readxl)
library(tidyverse)
military <- read_xlsx("../../practice_activities/gov_spending_per_capita.xlsx", 
                      sheet = "Share of Govt. spending", 
                      skip  = 7, 
                      n_max  = 191)

military_clean <- military |> 
  mutate(across(`1988`:`2019`, ~ na_if(.x, y = ". .")),
         across(`1988`:`2019`, ~ na_if(.x, y = "xxx"))
         )
```

Converts all names of variables in a data set to *snake_case*.

```{r}
#| eval: true
#| echo: true
#| code-line-numbers: "3-5"
names(military)

library(janitor)
military_clean_names <- military |> 
  clean_names()

names(military_clean_names)
```

## Lifceycle stages

[Learn more about lifecycle stages](https://lifecycle.r-lib.org/articles/stages.html) of packages, functions, function arguments in R.

::: columns
::: column
```{r}
#| fig-align: center
#| out-width: 80%
knitr::include_graphics("images/depreciated.PNG")
knitr::include_graphics("images/superseded.png")
```
:::

::: column
```{r}
#| fig-align: center
#| fig-cap: "Image source: deanattali.com/blog/cranalerts/"
#| out-width: "100%"
knitr::include_graphics("https://deanattali.com/assets/img/blog/cranalerts/automation.png")
```
:::
:::

## Deprecated Functions: Military Spending Example

```{r}
#| warning: true
#| message: true
#| echo: true
#| code-line-numbers: "2"
military_clean |> 
  filter(across(Notes:`2019`, is.na)) |> 
  slice_head(n = 3)
```

```{r}
#| echo: true
#| code-line-numbers: "2"
military_clean |>
  filter(if_all(Notes:`2019`, ~ is.na(.x))) |> 
  slice_head(n = 3)
```

## `dplyr` updates

There was an update to the `dplyr` package to Version 1.1.0 on Sunday 1/29/2023.

[See changelog for updates](https://dplyr.tidyverse.org/news/index.html)

![](images/dplyr-update.jpg)

## `group_by()` vs `.by =` argument

![](images/groupby-dplyr-update.jpg)

## `across()`

![](images/across-dplyr-update.jpg)

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "6-7"

military |> 
  mutate(across(`1988`:`2019`, na_if, y = ". ."))


military |> 
  mutate(across(`1988`:`2019`, ~ na_if(.x, y = ". .")))
```

## `join_by()`

![](images/joins-dplyr-update.jpg)

## Saving & Piping data joins

```{r}
#| eval: false
#| echo: true
genres_movies_joined <- inner_join(directors_genres, movies_directors)

genres_movies_joined <- directors_genres |> 
  inner_join(movies_directors)
```

# Extensions to Relational Data

## IMDb Movies Data

Multiple tables of data are called **relational data** because it is the *relations*, not just the individual data sets, that are important.

**Keys:**

-   Uniquely identifies an observation in a data set
-   Relate data sets to each other

![](images/imdb-keys.png)

## Joining Multiple Data Sets

::: panel-tabset
### movies_directors

```{r}
#| echo: true
movies_directors
```

### directors

```{r}
#| echo: true
directors
```

### movies

```{r}
#| echo: true
movies
```

### sketch

```{r}
#| out-width: "70%"
#| fig-align: center
knitr::include_graphics("images/imdb-multiple-joins.png")
```

### 1st + 2nd

```{r}
#| echo: true
join_one_data <- movies_directors |> 
  inner_join(directors, 
             by = c("director_id" = "id")
             )
join_one_data
```

If you update `dplyr`...

```{r}
#| echo: true
#| eval: false
#| code-line-numbers: "3"
directors_movie_ids <- movies_directors |> 
  inner_join(directors, 
             by = join_by(id == director_id)
             )
```

### + 3rd

```{r}
#| echo: true
join_two_data <- movies_directors |> 
  inner_join(directors, 
             by = c("director_id" = "id")
             ) |> 
  inner_join(movies,
             by = c("movie_id" = "id")
             ) |> 
  rename(movie_name = name)
join_two_data
```
:::

## Joining on Multiple Variables

Using the hiphop data from Lab 3...

```{r}
aae <- read_csv("../../lab_assignments/lab3/AAE.csv")
music <- aae |> 
  select(word, subj, folk:pop)

familiarity <- aae |> 
  select(word, subj, familiarity) |> 
  rename(participant = subj)
```

::: panel-tabset
## Music Taste

```{r}
#| echo: true
music
```

## Word Familiarity

```{r}
#| echo: true
familiarity
```

## Join by word + subj

::: columns
::: {.column width="55%"}
```{r}
#| echo: true
#| code-line-numbers: 3"-4"
music_wordfam <- music |> 
  full_join(familiarity,
            by = c("word" = "word", 
                   "subj" = "participant")
            )
music_wordfam 
```
:::

::: {.column width="45%"}
if `dplyr` updated...

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "3-4"
music_wordfam <- music |> 
  full_join(familiarity,
            by = join_by(word == word, 
                         subj == participant)
            )
music_wordfam 
```
:::
:::
:::

## Lab + Challenge

[Lab 4: Avocado Prices + Challenge 4: Avocado Toast Ate My Mortgage](https://earobinson95.github.io/stat331-calpoly/lab-assignments/lab4/lab4-avocado-prices.html)

<br> **Handy Helpers**

`rename()` -- Change names of columns

`separate()` -- Separate values of a variable

<br> **Filtering Joins**

`semi_join()`: Keeps values found in another data set

`anti_join()`: Keeps values not found in another data set

## Workflow

1.  Load packages + read in original data

```{r}
#| echo: true
#| eval: false
library(tidyverse)
data_original <- read_csv(file = "path/to/datal.csv")
```

2.  Clean data -- save your changes! This is now your new "master" data set

```{r}
#| echo: true
#| eval: false
data_clean <- data_original |> 
  mutate(across(x1:x5, ~ as.factor(.x))) |> 
  mutate(new_var <- if_else(...))
```

3.  If you need subsets, create those from your new "master" data for the specific tasks.

```{r}
#| echo: true
#| eval: false
demographics_subj <- data_clean |> 
  distinct(subj, keep_all = TRUE)
```

4.  Output **only** the the information you want to include in your assignment.

## To do...

-   **Lab 4: Avocado Prices**
    -   Due Friday, 2/3 at 11:59pm
-   **Challenge 4: Avocado Toast Ate My Mortgage**
    -   Due Saturday, 2/4 at 11:59pm
-   **Read Chapter 5: Special Data Types**
    -   **Concept Check 5.1 + 5.2 + 5.3** due Monday (2/6) at 8:00am
-   [**Bonus Challenge: Murder Mystery in SQL City**](https://earobinson95.github.io/stat331-calpoly/bonus-challenges/bonus-challenge-murder-in-sql-city.html)
    -   Due Sunday 2/12 at 11:59pm
